<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Awesome Chatbot</title>
  
  <subtitle>Blog by Handsome Geeks</subtitle>
  <link href="/awesome-chatbot/atom.xml" rel="self"/>
  
  <link href="https://bupt.github.io/awesome-chatbot/"/>
  <updated>2018-09-26T12:37:39.898Z</updated>
  <id>https://bupt.github.io/awesome-chatbot/</id>
  
  <author>
    <name>BUPTer</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>世界模型的解读</title>
    <link href="https://bupt.github.io/awesome-chatbot/2018/09/21/world-model-to-learn-them-all/"/>
    <id>https://bupt.github.io/awesome-chatbot/2018/09/21/world-model-to-learn-them-all/</id>
    <published>2018-09-20T16:00:00.000Z</published>
    <updated>2018-09-26T12:37:39.898Z</updated>
    
    <content type="html"><![CDATA[<script src="/awesome-chatbot/assets/js/APlayer.min.js"> </script><!-- 论文基本信息：方便查阅和追踪 --><!-- 论文基本信息的获取：从paperweekly首页上方搜索论文；若未检索到，点击推荐论文输入论文名即可自动获取信息--><h2 id="论文基本信息"><a href="#论文基本信息" class="headerlink" title="论文基本信息"></a>论文基本信息</h2><ol><li><p>论文名：World Models</p><!-- Ex: 1. 论文名：Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs. --></li><li><p>论文链接：<a href="https://arxiv.org/pdf/1803.10122.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1803.10122.pdf</a></p><!-- Ex: 2. https://arxiv.org/abs/1606.01541  --></li><li><p>论文源码：</p><ul><li><a href="https://worldmodels.github.io/" target="_blank" rel="noopener">https://worldmodels.github.io/</a></li></ul></li></ol><!--    - https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow    - https://github.com/agsarthak/Goal-oriented-Dialogue-Systems--><ol><li><p>关于作者：</p><!-- 建议从google schoolar获取详细信息  - first_author: position, times_cited--><ul><li>David Ha：</li><li>Jurgen Schimidhuber: LSTM之父，无需多言</li></ul></li><li><p>关于笔记作者：</p><ul><li>朱正源,北京邮电大学研究生，研究方向为多模态与认知计算。</li></ul></li></ol><h2 id="论文推荐理由"><a href="#论文推荐理由" class="headerlink" title="论文推荐理由"></a>论文推荐理由</h2><p>通过探索并且建立流行的强化学习环境的生成神经网络模型。<strong>世界模型</strong>可以在无监督的情况下快速训练，以学习环境的压缩时空表示。通过使用从世界模型中提取的特征作为Agent的输入，可以训练一个非常紧凑和简单的策略来解决所需的任务。甚至可以训练Agent完全在它自己的世界模型所产生的<strong>梦</strong>中，并将这个策略转移回实际环境中。</p><h2 id="世界模型"><a href="#世界模型" class="headerlink" title="世界模型"></a>世界模型</h2><h3 id="论文写作动机"><a href="#论文写作动机" class="headerlink" title="论文写作动机"></a>论文写作动机</h3><ol><li><p>哲学问题：人类究竟如何认识世界？<br> 人类通过有限的感知能力（眼睛、鼻子、耳朵、皮肤），逐渐建立一个自己的<strong>心智模型</strong>。人类的一切决策和动作则均根据每个人自己的内部模型的<strong>预测</strong>而产生。</p></li><li><p>人类如何处理日常生活的信息流？<br> 通过<strong>注意力机制</strong>学习客观世界时空方面的抽象表达。</p></li><li><p>人类的潜意识如何工作？<br> 以棒球为例子，击球手在如此短的时间（短于视觉信号到达大脑的时间！）内需要作出何时击球的动作。<br> 人类可以完成击球的原因便是因为人类天生的心智模型可以预测棒球的运动路线。</p></li><li><p>我们是否可以让模型根据环境自觉建立特有的模型进行自学习？</p></li><li><p>Jurgen历史性的工作总结：强化学习背景下的RNN-based世界模型!</p></li></ol><h3 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h3><h4 id="总览Agent模型"><a href="#总览Agent模型" class="headerlink" title="总览Agent模型"></a>总览Agent模型</h4><ol><li><p>视觉感知元件：<strong>压缩</strong>视觉获取到的信息</p></li><li><p>记忆元件：根据历史信息对客观环境进行<strong>预测</strong></p></li><li><p>决策模块：根据视觉感知元件和记忆元件选择<strong>行动</strong></p></li></ol><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvm2l4tc84j20wf0ledkn.jpg" alt=""></p><h4 id="VAE-V-Model"><a href="#VAE-V-Model" class="headerlink" title="VAE(V) Model"></a>VAE(V) Model</h4><p>Agent通过VAE可以从观察的每一帧中学习出抽象的、压缩的表示。</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvm3sg25puj20wn09zq7g.jpg" alt=""></p><h4 id="MDN-RNN-M-Model"><a href="#MDN-RNN-M-Model" class="headerlink" title="MDN-RNN(M) Model"></a>MDN-RNN(M) Model</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvmurcu30uj20u10l8jta.jpg" alt=""><br>其中下一时刻的预测$z_{t+1}$使用概率的形式表示为$P(z_{t+1}|a_t,z_t,h_t)$,其中$a_t$是在$t$时刻的动作。<br>并且在采样阶段，通过调整温度参数$\tau$来控制模型的模糊度。(这个参数对后续训练控制器环节十分有效)</p><p>模型最上方的<strong>MDN</strong>表示<strong>Mixture Density Network</strong>。</p><h4 id="Controller-C-Model"><a href="#Controller-C-Model" class="headerlink" title="Controller(C) Model"></a>Controller(C) Model</h4><p>这个模块用来根据最大累计Reward决定Agent下一个时刻的行动。论文中故意将这个模块设置的尽量小并且简单。</p><p>因此控制器是一个简单的单层线性模型：<br>$$a_t=W_c[z_t h_t]+b_c$$</p><p>特别指出，优化控制器参数的方法不是传统的梯度下降，而是<strong>Covariance-Matrix Adaptation Evolution Strategy</strong></p><h4 id="结合三个模块"><a href="#结合三个模块" class="headerlink" title="结合三个模块"></a>结合三个模块</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvmvf1dkd5j20p50ic77b.jpg" alt=""></p><p>通过伪代码表示模型:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rollout</span><span class="params">(controller)</span>:</span></span><br><span class="line">  obs = env.reset()</span><br><span class="line">  h = rnn.initial_state()</span><br><span class="line">  done = <span class="keyword">False</span></span><br><span class="line">  cumulative_reward = <span class="number">0</span></span><br><span class="line">  <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">    z = vae.encode(obs)</span><br><span class="line">    a = controller.action([z, h])</span><br><span class="line">    obs, reward, done = env.step(a)</span><br><span class="line">    cumulative_reward += reward</span><br><span class="line">    h = rnn.forward([a, z, h])</span><br><span class="line">  <span class="keyword">return</span> cumulative_reward</span><br></pre></td></tr></table></figure></p><h3 id="实验设计1"><a href="#实验设计1" class="headerlink" title="实验设计1"></a>实验设计1</h3><p>两个实验的环境均选自<code>OpenAI Gym</code></p><h4 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h4><p>CarRacing-v0(Car Racing Experiment)</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvmw8osn7xj20vh0kt43n.jpg" alt=""></p><p>动作空间有</p><ol><li>左转</li><li>右转</li><li>加速</li><li>刹车</li></ol><h4 id="实验实现流程"><a href="#实验实现流程" class="headerlink" title="实验实现流程"></a>实验实现流程</h4><ol><li>根据随机的策略收集10，000次游戏过程</li><li>根据每个游戏过程的每一帧训练VAE模型，输出结果为$z\in \mathcal{R}^{32}$</li><li>训练MDN-RNN模型，输出结果为$P(z_{t+1}|a_t,z_t,h_t)$</li><li>定义控制器（c）,$a_t=W_c[z_t h_t]+b_c$</li><li>使用CMS-ES算法得到最大化累计Reward的$$W_b$与$b_c$</li></ol><p>模型参数共有：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvmwg6zv1ej20gg063jru.jpg" alt=""></p><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><ol><li><p>只添加V Model(VAE)<br>如果没有M Model(MDN-RNN)模块，控制器的公式便为：$a_t=W_{c}z_t+b_c$。<br>实验结果表明这会导致Agent不稳定的驾驶行为。<br>在这种情况下，尝试控制器添加一层隐含层，虽然实验效果有所提升，但是仍然没能达到很好的效果。</p></li><li><p>世界模型完全体（VAE+MDN-RNN）<br>实验结果表明，Agent驾驶得更加稳定。<br>因为$h_t$包含了当前环境关于未来信息的概率分布，因此Agent可以向一级方程式选手和棒球手一样迅速做出判断。</p></li><li><p>世界模型与其他模型的对比：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvmxb7t9zdj20op09odi1.jpg" alt=""></p></li><li><p>对世界模型当前状态$z_{t+1}$进行可视化<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvmxeae7jyj20g00g4jwu.jpg" alt=""><br>上图将$\tau$设置为0.25（这个参数可以调节生成环境的模糊程度）</p></li></ol><h3 id="实验设计2"><a href="#实验设计2" class="headerlink" title="实验设计2"></a>实验设计2</h3><p><strong>我们是否可以让Agent在自己的梦境中学习，并且改变其对真实环境的策略</strong><br>如果世界模型对其<strong>目的</strong>有了充分的认识，那么我们就可以使用世界代替Agent真实观察到的环境。（类比我们下楼梯的时候，根本不需要小心翼翼地看着楼梯）<br>最终，Agent将不会直接观察到现实世界，而只会看到世界模型<strong>让</strong>它看到的事物。</p><h4 id="实验环境-1"><a href="#实验环境-1" class="headerlink" title="实验环境"></a>实验环境</h4><p>VizDoom Experiment</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvmxq3o7ihj20g10bywio.jpg" alt=""></p><p>游戏目的是控制Agent躲避怪物发出的火球。</p><h4 id="实验实现流程-1"><a href="#实验实现流程-1" class="headerlink" title="实验实现流程"></a>实验实现流程</h4><p>模型的M Model(MDN-RNN)主要负责预测Agent下一时刻（帧）是否会死亡。<br>当Agent在其世界模型中进行训练的时候，便不需要V Model对真实环境的像素进行编码了。</p><ol><li>从随机策略中选取10，000局游戏（同实验一）</li><li>根据每次游戏的每一帧训练VAE模型，得到$z\in \mathcal{R}^{64}$($z$的维度变成了64)，之后使用VAE模型将收集的图像转换为隐空间表示。</li><li>训练MDN-RNN模型，输出结果为$P(z_{t+1},d_{t+1}|a_t,z_t,h_t)$</li><li>定义控制器为$a_t=W_c[z_t h_t]$</li><li>使用CMA-ES算法从世界模型构建的虚拟环境中得到最大化累计生存时间的$W_c$</li></ol><p>模型的参数共有：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fvn0lmh3rdj20li07dwf8.jpg" alt=""></p><h4 id="模糊化世界模型"><a href="#模糊化世界模型" class="headerlink" title="模糊化世界模型"></a>模糊化世界模型</h4><p>通过增加模糊度参数$\tau$，会使得游戏变得更难（世界模型生成的环境更加模糊）。<br>如果Agent在高模糊度参数表现的很好的话，那么在正常模式下通常表现的更好。</p><p>也就是说，即使<strong>V model(VAE)不能够正确的捕捉每一帧全部的信息</strong>，Agent也能够完成真实环境给定的任务。</p><p>实验结果表明，模糊度参数太低相当于没有利用这个参数，但是太高的话模型又相当于”近视“了。因此需要找到一个合适的模糊度参数值。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h4 id="泛化：迭代式训练程序"><a href="#泛化：迭代式训练程序" class="headerlink" title="泛化：迭代式训练程序"></a>泛化：迭代式训练程序</h4><ol><li>随机初始化M Model(MDN-RNN)和C Model(Controller)的参数</li><li>对真实环境进行N次试验。保存每次试验的动作$a_t$和观察$x_t$</li><li>训练M Model(MDN-RNN)，得到$P(x_{t+1},r_{t+1},a_{t+1},d_{t+1}|x_t,a_t,h_t)$；训练C Model(Controller)并且M中的最优化期望rewards。</li><li>回到第2步如果任务没有结束</li></ol><p>这个泛化程序的特点是从M model中不仅仅要得到预测的观察$x$和是否结束任务$done$，</p><p>一般的seq2seq模型，倾向于生成安全、普适的响应，因为这种响应更符合语法规则，在训练集中出现频率也较高，最终生成的概率也最大，而有意义的响应生成概率往往比他们小。通过MMI来计算输入输出之间的依赖性和相关性，可以减少模型对他们的生成概率。</p><h4 id="从信息到记忆：海马体的魔术"><a href="#从信息到记忆：海马体的魔术" class="headerlink" title="从信息到记忆：海马体的魔术"></a>从信息到记忆：海马体的魔术</h4><p>神经科学的研究（2017 Foster）发现了海马体重映现象：当动物休息或者睡觉的时候，其大脑会重新放映最近的经历。并且海马体重映现象对巩固记忆十分重要。</p><h4 id="注意力：只关心任务相关的特征"><a href="#注意力：只关心任务相关的特征" class="headerlink" title="注意力：只关心任务相关的特征"></a>注意力：只关心任务相关的特征</h4><p>神经科学的研究（2013 Pi）发现，主要视觉神经元只有在受到奖励的时候才会被从抑制状态激活。这表明人类通常从任务相关的特征中学习，而非接收到的所有特征。（该结论至少在成年人中成立）</p><h4 id="未来的展望"><a href="#未来的展望" class="headerlink" title="未来的展望"></a>未来的展望</h4><p>当前的问题主要出现在M Model(MDN-RNN)上：受限于RNN模型的信息存储能力。人类的大脑能够存储几十年甚至几百年的记忆，但是神经网络会因为梯度消失导致训练困难。</p><p>如果想让Agent可以探索更加复杂的世界，那么未来的工作可能是设计出一个可以<strong>代替MDN-RNN结构的模型</strong>，或者开发出一个<strong>外部记忆模块</strong>。</p><h3 id="引用与参考"><a href="#引用与参考" class="headerlink" title="引用与参考"></a>引用与参考</h3><ol><li><a href="https://arxiv.org/pdf/1803.10122.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1803.10122.pdf</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/awesome-chatbot/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;!-- 论文基本信息：方便查阅和追踪 --&gt;
&lt;!-- 论文基本信息的获取：从paperweekly首页上方搜索论文；若未检索到，点击推荐论文输入
      
    
    </summary>
    
      <category term="AI" scheme="https://bupt.github.io/awesome-chatbot/categories/AI/"/>
    
    
      <category term="note" scheme="https://bupt.github.io/awesome-chatbot/tags/note/"/>
    
      <category term="JurgenSchmidhuber" scheme="https://bupt.github.io/awesome-chatbot/tags/JurgenSchmidhuber/"/>
    
  </entry>
  
  <entry>
    <title>对话AI的论文列表</title>
    <link href="https://bupt.github.io/awesome-chatbot/2018/08/09/convAI-paper-list/"/>
    <id>https://bupt.github.io/awesome-chatbot/2018/08/09/convAI-paper-list/</id>
    <published>2018-08-09T04:31:31.000Z</published>
    <updated>2018-09-04T06:19:31.740Z</updated>
    
    <content type="html"><![CDATA[<script src="/awesome-chatbot/assets/js/APlayer.min.js"> </script><blockquote><p>论文列表格式<br>&emsp;论文发表年份： 论文题目&amp;论文链接：第一作者（第一作者所属学校/机构），代码链接</p></blockquote><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="Existing-Models-of-Dialog-System"><a href="#Existing-Models-of-Dialog-System" class="headerlink" title="Existing Models of Dialog System"></a>Existing Models of Dialog System</h3><h4 id="Task-Oriented-Dialog"><a href="#Task-Oriented-Dialog" class="headerlink" title="Task-Oriented Dialog"></a>Task-Oriented Dialog</h4><ul><li>13: <a href="https://ieeexplore.ieee.org/document/6407655/" target="_blank" rel="noopener"><strong>POMDP-Based Statistical Spoken Dialog Systems: A Review</strong></a>: Steve Young(Cambridge University)</li><li>11: <a href="https://www.wiley.com/en-us/Spoken+Language+Understanding:+Systems+for+Extracting+Semantic+Information+from+Speech-p-9780470688243" target="_blank" rel="noopener"><strong>Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</strong></a>: Book!</li><li>11:<a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener"><strong>Data-Driven Response Generation in Social Media</strong></a>: Alan Ritter(University of Washington Seattle)</li><li><p>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener"><strong>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</strong></a>: Alessandro Sordoni(Universite de Montreal)</p></li><li><p>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener"><strong>A Neural Conversational Model</strong></a>: Oriol Vinyals(Google), <a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</p></li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener"><strong>Neural Responding Machine for Short-Text Conversation</strong></a>: Lifeng Shang(Noah’s Ark Lab), <a href="https://github.com/stamdlee/DeepLearningFramework" target="_blank" rel="noopener"><strong>code</strong></a> via theano and tensorflow</li></ul><h3 id="Traditional-NLP-component-stack"><a href="#Traditional-NLP-component-stack" class="headerlink" title="Traditional NLP component stack"></a>Traditional NLP component stack</h3><h4 id="Challenge-of-NLP"><a href="#Challenge-of-NLP" class="headerlink" title="Challenge of NLP"></a>Challenge of NLP</h4><ul><li>09: <a href="https://www.cs.colorado.edu/~martin/slp.html" target="_blank" rel="noopener"><strong>SPEECH and LANGUAGE PROCESSING An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Second Edition</strong></a>: book </li></ul><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h4 id="application-scenarios"><a href="#application-scenarios" class="headerlink" title="application scenarios"></a>application scenarios</h4><ol><li>Web search<ul><li>13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), <a href="https://github.com/wangtianqi1993/DL-WebSearch" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</li><li>14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li></ul></li><li>Entity linking<ul><li>14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Image captioning<ul><li>15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul></li><li>Machine Translation<ul><li><a href="http://aclweb.org/anthology/P/P14/P14-1066.pdf" target="_blank" rel="noopener"><strong>Learning Continuous Phrase Representations for Translation Modeling</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Online recommendation<ul><li>[<strong>duplicate</strong>] 14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfneg Gao(Microsoft Research)</li></ul></li></ol><h4 id="Framework-of-Model"><a href="#Framework-of-Model" class="headerlink" title="Framework of Model"></a>Framework of Model</h4><ul><li>[<strong>duplicate</strong>] 13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), [<strong>code</strong>]</li><li>[<strong>duplicate</strong>] 14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li><li><a href="http://aka.ms/sent2vec" target="_blank" rel="noopener">Sent2Vec</a>: software by microsoft</li></ul><h4 id="Go-beyound-DSSM"><a href="#Go-beyound-DSSM" class="headerlink" title="Go beyound DSSM"></a>Go beyound DSSM</h4><ul><li>[<strong>duplicate</strong>] 15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul><hr><h2 id="Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC"><a href="#Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC" class="headerlink" title="Question answeriing(QA) and Machine Readiing Comprehension(MRC)"></a>Question answeriing(QA) and Machine Readiing Comprehension(MRC)</h2><h3 id="Open-Domain-Question-Answering"><a href="#Open-Domain-Question-Answering" class="headerlink" title="Open-Domain Question Answering"></a>Open-Domain Question Answering</h3><h4 id="Knowledge-Base-QA"><a href="#Knowledge-Base-QA" class="headerlink" title="Knowledge Base-QA"></a>Knowledge Base-QA</h4><ol><li>Symbolic approach via Large-scale knowledge graphs<ul><li>[<strong>oral</strong>] 98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>: Stephen D.Richardson(Microsoft Research)</li><li>[<strong>oral</strong>] 13: <a href="http://www.aclweb.org/anthology/D13-1160" target="_blank" rel="noopener">Semantic Parsing on Freebase from Question-Answer Pairs</a>: Jonathan Berant(Stanford University)</li><li>15: <a href="https://arxiv.org/pdf/1510.08565.pdf" target="_blank" rel="noopener">Attention with Intention for a Neural Network Conversation Model</a>: Kaisheng Yao(Microsoft Research)</li><li>14: <a href="http://www.aclweb.org/anthology/P14-1091" target="_blank" rel="noopener">Knowledge-Based Question Answering as Machine Translation</a>: Junwei Bao(Harbin Institute of Technology)</li><li>15: <a href="http://aclweb.org/anthology/P15-1128" target="_blank" rel="noopener">Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base</a>:Wen-tau Yih(Microsoft Research)</li></ul></li><li><p><strong>ReasoNet</strong> with Shared Memory</p><ul><li>[<strong>oral</strong>][<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Search Controller in <strong>ReasoNet</strong> </p><ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li></ul></li><li><strong>ReasoNet</strong> in symbolic vs neural space<ul><li>Symbolic is comprehensible but not robust<ul><li>11: <a href="http://www.cs.cmu.edu/~tom/pubs/lao-emnlp11.pdf" target="_blank" rel="noopener">Random Walk Inference and Learning in A Large Scale Knowledge Base</a>:Ni Lao(Carnegie Mellon University)</li><li>98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>:Stephen D.Richardson(Microsoft Research)</li></ul></li><li>Neural is robust but not comprehensible<ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>[<strong>oral</strong>] 15: <a href="https://arxiv.org/abs/1412.6575" target="_blank" rel="noopener">EMBEDDING ENTITIES AND RELATIONS FOR LEARNING AND INFERENCE IN KNOWLEDGE BASES</a>:Bishan Yang(Cornell University), <a href="https://github.com/thunlp/OpenKE/blob/master/models/DistMult.py" target="_blank" rel="noopener">TensorFlow code</a>, <a href="https://github.com/thunlp/OpenKE/blob/OpenKE-PyTorch/models/DistMult.py" target="_blank" rel="noopener">PyTorch code</a></li></ul></li><li>Hybrid is robust and  comprehensible<ul><li>18: <a href="https://arxiv.org/pdf/1802.04394.pdf" target="_blank" rel="noopener">M-Walk: Learning to Walk in Graph with Monte Carlo Tree Search</a>:Yelong Shen(Microsoft Research&amp;Tecent AI Lab)</li><li>18: [<strong>oral</strong>] <a href="https://arxiv.org/abs/1707.06690" target="_blank" rel="noopener">DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning</a>:Wenhan Xiong(University of California,Santa Barbara), <a href="https://github.com/xwhan/DeepPath" target="_blank" rel="noopener">code1</a> <a href="https://github.com/arunarn2/DeepPathwithTensorforce" target="_blank" rel="noopener">code2</a></li><li>18: <a href="https://arxiv.org/abs/1711.05851" target="_blank" rel="noopener">GO FOR A WALK AND ARRIVE AT THE ANSWER: REASONING OVER PATHS IN KNOWLEDGE BASES USING REINFORCEMENT LEARNING</a>:Rajarshi Das(University of Massachusetts,Amherst), </li></ul></li></ul></li><li>Multi-turn KB-QA<ul><li><del>Programmed Dialogue policy</del><ul><li><del>15: <a href="https://arxiv.org/pdf/1504.07182.pdf" target="_blank" rel="noopener">A Probabilistic Framework for Representing Dialog Systems and Entropy-Based Dialog Management through Dynamic Stochastic State Evolution</a>:Ji Wu(IEEE)</del></li></ul></li><li>Trained via RL Dialogue policy<ul><li>16: <a href="https://arxiv.org/abs/1512.01337" target="_blank" rel="noopener">Neural Generative Question Answering </a>:Jun Yin(Noah’s Ark Lab, Huawe) <a href="https://github.com/jxfeb/Generative_QA" target="_blank" rel="noopener">corpus</a></li><li>[<strong>oral</strong>] 16: <a href="https://arxiv.org/abs/1604.04562" target="_blank" rel="noopener">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>:Tsung-Hsien Wen(Cambridge University), <a href="https://github.com/shawnwun/NNDIAL" target="_blank" rel="noopener">Theano code</a></li><li>[<strong>oral</strong>] 17: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University), <a href="https://github.com/MiuLab/KB-InfoBot" target="_blank" rel="noopener">Theano code</a></li></ul></li></ul></li></ol><h4 id="Text-QA"><a href="#Text-QA" class="headerlink" title="Text-QA"></a>Text-QA</h4><ol><li>MS MARCO<ul><li>16: <a href="https://arxiv.org/abs/1611.09268" target="_blank" rel="noopener">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</a>:Tri Nguyan(Microsoft AI&amp;Research)</li></ul></li><li>SQuAD<ul><li>16: <a href="https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf" target="_blank" rel="noopener">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a>:Pranav Rajpurkar(Stanford University)</li></ul></li></ol><h3 id="Neural-MRC-Models"><a href="#Neural-MRC-Models" class="headerlink" title="Neural MRC Models"></a>Neural MRC Models</h3><h4 id="BiDAF"><a href="#BiDAF" class="headerlink" title="BiDAF"></a>BiDAF</h4><ul><li>16: <a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION</a>:Minjoon Seo(University of Washington)<ul><li><a href="https://github.com/imraviagrawal/ReadingComprehension" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/bentrevett/bidaf" target="_blank" rel="noopener">code2</a> </li><li><a href="https://github.com/akhil-vader/MachineComprehension_SQuAD" target="_blank" rel="noopener">code3</a> </li><li><a href="https://github.com/RamkishanPanthena/Machine-Comprehension-using-SQuAD-Dataset" target="_blank" rel="noopener">code4</a></li></ul></li></ul><h4 id="SAN"><a href="#SAN" class="headerlink" title="SAN"></a>SAN</h4><ul><li>18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul><h4 id="Neural-MRC-Models-on-SQuAD"><a href="#Neural-MRC-Models-on-SQuAD" class="headerlink" title="Neural MRC Models on SQuAD"></a><strong>Neural MRC Models on SQuAD</strong></h4><ol><li><p>Encoding: map each text span to a semantic vector</p><ul><li>Word Embedding<ul><li>14: <a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a>:Jeffrey Pennington(Stanford University)<ul><li><a href="https://github.com/brangerbriz/midi-glove" target="_blank" rel="noopener">code:midi-glove</a></li><li><a href="https://github.com/fdurant/wiki_glove" target="_blank" rel="noopener">code:wiki-glove</a></li></ul></li><li>13: <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Distributed Representations of Words and Phrases and their Compositionality</a>:Tomas Mikolov(Google Inc.)<ul><li><a href="https://github.com/brijml/mikolov_word2vec" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/shuuchen/keras_word2vec" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li><li><p>Context Embedding</p><ol><li><p>capture context info for each word</p><ul><li>16: <a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li><li>18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li><li><p>Context Embedding via BiLSTM/ELmo</p><ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>17: <a href="https://arxiv.org/abs/1708.00107" target="_blank" rel="noopener">Learned in Translation: Contextualized Word Vectors</a>:Bryan McCann(SalesForce)</li><li>16: [duplicate]<a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li></ul></li><li><p>Context Embedding</p><ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li></ol></li></ul><ul><li>Query-context/Content-query attention</li></ul></li><li><p>Reasoning: rank and re-rank semantic vectors</p><ul><li><p>Multi-step reasoning for Text-QA</p><ul><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Stochastic Answer Net</p><ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul></li></ul></li></ol><hr><h2 id="Task-oriented-dialogues"><a href="#Task-oriented-dialogues" class="headerlink" title="Task-oriented dialogues"></a>Task-oriented dialogues</h2><h3 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h3><h4 id="A-Example-Dialogue-with-Movie-Bot"><a href="#A-Example-Dialogue-with-Movie-Bot" class="headerlink" title="A Example Dialogue with Movie-Bot"></a>A Example Dialogue with Movie-Bot</h4><ul><li><a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">source code</a></li></ul><h4 id="Conversation-as-Reinforcement-Learning"><a href="#Conversation-as-Reinforcement-Learning" class="headerlink" title="Conversation as Reinforcement Learning"></a>Conversation as Reinforcement Learning</h4><ul><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li><li>00: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li></ul><h4 id="Dialogue-System-Evaluation-Simulated-Users"><a href="#Dialogue-System-Evaluation-Simulated-Users" class="headerlink" title="Dialogue System Evaluation(Simulated Users)"></a>Dialogue System Evaluation(Simulated Users)</h4><ol><li>Agenda based<ul><li>09: <a href="https://ieeexplore.ieee.org/document/4806280/" target="_blank" rel="noopener">The Hidden Agenda User Simulation Model</a>:Jost Schatzmann(IEEE)</li><li><a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">source code</a> </li></ul></li><li>Model based<ul><li>16: <a href="https://arxiv.org/abs/1607.00070" target="_blank" rel="noopener">A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems</a>: Layla El Asri(Maluuba Research)</li><li>17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul></li></ol><h3 id="traditional-approache"><a href="#traditional-approache" class="headerlink" title="traditional approache"></a>traditional approache</h3><h4 id="Decison-theoretic-View-of-Dialogue-Management"><a href="#Decison-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decison-theoretic View of Dialogue Management"></a>Decison-theoretic View of Dialogue Management</h4><ul><li>[<strong>duplicate</strong>] 00: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li><li>00: <a href="http://www.aclweb.org/anthology/P98-2219" target="_blank" rel="noopener">Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email</a>: Marilyn A.Walker(ATT Labs Research)</li><li>02: <a href="https://dl.acm.org/citation.cfm?id=1289246" target="_blank" rel="noopener">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li></ul><h4 id="Language-Understanding-Uncertainty-POMDP-as-a-principled-framework"><a href="#Language-Understanding-Uncertainty-POMDP-as-a-principled-framework" class="headerlink" title="Language Understanding Uncertainty: POMDP as a principled framework"></a>Language Understanding Uncertainty: POMDP as a principled framework</h4><ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">Spoken Dialogue Management Using Probabilistic Reasoning</a>: Nicholas Roy(Carnegie Mellon University)</li><li>01: <a href="http://www.wytsg.org:88/reslib/400/180/110/020/010/130/L000000000233767.pdf" target="_blank" rel="noopener">Spoken Dialogue Management as Planning and Acting under Uncertainty</a>:Bo Zhang(Tech. of China)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li></ul><h4 id="scaling-up-Dialogue-Optimization"><a href="#scaling-up-Dialogue-Optimization" class="headerlink" title="scaling up Dialogue Optimization"></a>scaling up Dialogue Optimization</h4><ol><li>Use approxmiate POMDP algorithms leveraging problem-specific structure<ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li></ul></li><li>Use Reinforcement Learning algorithms with function approximation<ul><li>08: <a href="http://www.aclweb.org/anthology/J08-4002" target="_blank" rel="noopener">Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets</a>: James Henderson</li><li>09: <a href="https://pdfs.semanticscholar.org/a950/d7836e101e7d649791714d8383a804a6f671.pdf" target="_blank" rel="noopener">Reinforcement Learning for Dialog Management using Least-Squares Policy Iteration and Fast Feature Selection</a>: Lihong Li(Rutgers University)</li><li>14: <a href="http://mi.eng.cam.ac.uk/~sjy/papers/gktb14.pdf" target="_blank" rel="noopener">Incremental on-line adaptation of POMDP-based dialogue managers to extended domains</a>:M.Gasic[Cambridge University]</li></ul></li></ol><h3 id="Natural-language-understanding-and-dialogue-state-tracking"><a href="#Natural-language-understanding-and-dialogue-state-tracking" class="headerlink" title="Natural language understanding and dialogue state tracking"></a>Natural language understanding and dialogue state tracking</h3><h4 id="Language-Understanding"><a href="#Language-Understanding" class="headerlink" title="Language Understanding"></a>Language Understanding</h4><ol><li><p>DNN for Domain/Intent Classification</p><ul><li>15:  <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/RNNLM_addressee.pdf" target="_blank" rel="noopener">Recurrent Neural Network and LSTM Models for Lexical Utterance Classification</a>: Suman Raviuri(University of California,Berkeley)</li></ul></li><li><p>Slot filling</p><ul><li>16: <a href="https://www.csie.ntu.edu.tw/~yvchen/doc/IS16_MultiJoint.pdf" target="_blank" rel="noopener">Multi-Domain Joint Semantic Frame Parsing using Bi-directional RNN-LSTM</a>: Dilek Hakkani-Tur(Microsoft Research)</li></ul></li><li><p>Further details on NLU</p><ul><li><a href="https://www.csie.ntu.edu.tw/~yvchen/doc/OpenDialogue_Tutorial_IJCNLP.pdf" target="_blank" rel="noopener">ppt</a></li><li>E2E MemNN for Contectual LU: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/IS16_ContextualSLU.pdf" target="_blank" rel="noopener">End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding</a>: Yun-Nung Chen(National Taiwan University )</li><li>[<strong>duplicate</strong>] LU Importance: 17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul></li></ol><h4 id="Dialogue-State-Tracking-DST"><a href="#Dialogue-State-Tracking-DST" class="headerlink" title="Dialogue State Tracking(DST)"></a>Dialogue State Tracking(DST)</h4><ol><li>DSTC(Dialog State Tracking Challenge)<ul><li><a href="https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/" target="_blank" rel="noopener">DSTC1 official website</a></li><li><a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="noopener">DSTC2&amp;3 official website</a></li><li><a href="http://www.colips.org/workshop/dstc4/" target="_blank" rel="noopener">DSTC4 official website</a></li><li><a href="http://workshop.colips.org/dstc5/" target="_blank" rel="noopener">DSTC5 official website</a></li></ul></li><li><p>Neural Belief Tracker</p><ul><li>16: <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li></ul></li><li><p>NN-Based DST</p><ul><li>13: <a href="http://www.anthology.aclweb.org/W/W13/W13-4073.pdf" target="_blank" rel="noopener">Deep Neural Network Approach for the Dialog State Tracking Challenge</a>: Matthew Henderson(University of Cambridge)</li><li>15: <a href="https://arxiv.org/abs/1506.07190" target="_blank" rel="noopener">Multi-domain Dialog State Tracking using Recurrent Neural Networks</a>: Nikola Mrksic(University of Cambridge)</li><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li></ul></li></ol><h3 id="Deep-RL-for-dialogue-policy-learning"><a href="#Deep-RL-for-dialogue-policy-learning" class="headerlink" title="Deep RL for dialogue policy learning"></a>Deep RL for dialogue policy learning</h3><h4 id="Two-main-classed-of-RL-algorithms"><a href="#Two-main-classed-of-RL-algorithms" class="headerlink" title="Two main classed of RL algorithms"></a>Two main classed of RL algorithms</h4><ol><li>Value function based:<ul><li>15: <a href="https://www.nature.com/articles/nature14236" target="_blank" rel="noopener">Human-level control through deep reinforcement learning</a>: Volodymyr Minh<ul><li><a href="https://github.com/devsisters/DQN-tensorflow" target="_blank" rel="noopener">code1</a> by tensorflow</li><li><a href="https://github.com/pianomania/DQN-pytorch" target="_blank" rel="noopener">code2</a> by pytorch</li></ul></li><li>16: <a href="https://arxiv.org/pdf/1606.02560.pdf" target="_blank" rel="noopener">Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning</a>: Tiancheng Zhao(Carnegie Mellon University)</li></ul></li><li>Policy based:<ul><li>92: <a href="https://doi.org/10.1007/BF00992696" target="_blank" rel="noopener">Simple statistical gradient-following algorithms for connectionist reinforcement learning</a>: Ronald J.Williams</li><li>17: <a href="http://www.aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="noopener">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a>: Pei-Hao Su(University of Cambridge)</li></ul></li></ol><h4 id="Domain-Extension-and-Exploration-BBQ-network"><a href="#Domain-Extension-and-Exploration-BBQ-network" class="headerlink" title="Domain Extension and Exploration(BBQ network)"></a>Domain Extension and Exploration(BBQ network)</h4><ul><li>18: <a href="https://arxiv.org/pdf/1608.05081.pdf" target="_blank" rel="noopener">BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems</a>: Zachary Lipton(Carnegir Mellon University)</li></ul><h4 id="Composite-task-Dialogues"><a href="#Composite-task-Dialogues" class="headerlink" title="Composite-task Dialogues"></a>Composite-task Dialogues</h4><ol><li>A Hierarchical Policy Learner<ul><li>98: <a href="http://papers.nips.cc/paper/1384-reinforcement-learning-with-hierarchies-of-machines.pdf" target="_blank" rel="noopener">Reinforcement Learning with Hierarchies of Machines</a>: Ronald Parr(UC Berkeley)</li><li>17: <a href="https://arxiv.org/abs/1704.03084" target="_blank" rel="noopener">Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning</a>: Baolin Peng(Microsoft Research)</li></ul></li><li>Integrating Planning for Dialogue Policy Learning<ul><li>18: <a href="https://arxiv.org/abs/1801.06176" target="_blank" rel="noopener">Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning</a>: Baolin Peng(Microsoft Research) , <a href="https://github.com/MiuLab/DDQ" target="_blank" rel="noopener">code</a></li></ul></li></ol><h3 id="Decision-theoretic-View-of-Dialogue-Management"><a href="#Decision-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decision-theoretic View of Dialogue Management"></a>Decision-theoretic View of Dialogue Management</h3><h4 id="Hybrid-Code-Networks"><a href="#Hybrid-Code-Networks" class="headerlink" title="Hybrid Code Networks"></a>Hybrid Code Networks</h4><ul><li>17: <a href="https://arxiv.org/abs/1702.03274" target="_blank" rel="noopener">Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</a>: Jason D. Williams(Microsoft Research)</li></ul><h4 id="Differentiating-KB-Accesses"><a href="#Differentiating-KB-Accesses" class="headerlink" title="Differentiating KB Accesses"></a>Differentiating KB Accesses</h4><ul><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University)</li></ul><h4 id="An-E2E-Neural-Dialogue-System"><a href="#An-E2E-Neural-Dialogue-System" class="headerlink" title="An E2E Neural Dialogue System"></a>An E2E Neural Dialogue System</h4><ul><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul><hr><h2 id="Fully-data-driven-conversation-models-and-chatbots"><a href="#Fully-data-driven-conversation-models-and-chatbots" class="headerlink" title="Fully data-driven conversation models and chatbots"></a>Fully data-driven conversation models and chatbots</h2><h3 id="Historical-overview"><a href="#Historical-overview" class="headerlink" title="Historical overview"></a>Historical overview</h3><h4 id="Response-retrival-system"><a href="#Response-retrival-system" class="headerlink" title="Response retrival system"></a>Response retrival system</h4><ul><li>10: <a href="https://aritter.github.io/chat.pdf" target="_blank" rel="noopener">Filter, Rank, and Transfer the Knowledge: Learning to Chat</a>:<br>Alan Ritter(University of Washington)</li></ul><h4 id="Response-generation-using-Statistical-Machine-Translation"><a href="#Response-generation-using-Statistical-Machine-Translation" class="headerlink" title="Response generation using Statistical Machine Translation"></a>Response generation using Statistical Machine Translation</h4><ul><li>11:  <a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener">Data-Driven Response Generation in Social Media</a>: Alan Ritter(University of Washington)</li></ul><h4 id="First-neural-response-generation-systems"><a href="#First-neural-response-generation-systems" class="headerlink" title="First neural response generation systems"></a>First neural response generation systems</h4><ol><li>Neural Models for Response Generation<ul><li>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>: Alessandro Sordoni(University de Montreal)</li><li>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener">A Neural Conversational Model</a>: Oriol Vinyals(Google .Inc)</li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener">Neural Responding Machine for Short-Text Conversation</a>: Lifeng Shang(Noah’s Ark Lab), <a href="https://github.com/stamdlee/DeepLearningFramework" target="_blank" rel="noopener">code</a></li></ul></li><li>Neural conversation engine: <ul><li>16: <a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)</li></ul></li></ol><h3 id="challenges-and-remedies"><a href="#challenges-and-remedies" class="headerlink" title="challenges and remedies"></a>challenges and remedies</h3><h4 id="Challenge-The-blandness-problem"><a href="#Challenge-The-blandness-problem" class="headerlink" title="Challenge: The blandness problem"></a>Challenge: The blandness problem</h4><ul><li>[<strong>duplicate</strong>] 16: <a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)</li></ul><h4 id="Challenge-The-consistency-problem"><a href="#Challenge-The-consistency-problem" class="headerlink" title="Challenge: The consistency problem"></a>Challenge: The consistency problem</h4><ol><li>Solution: Personalized Response Generation<ul><li>Microsoft Personality chat:speaker embedding LSTM: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model" target="_blank" rel="noopener">code</a> via Pytorch</li></ul></li><li>Personal modeling as multi-task learning<ul><li>17: <a href="https://arxiv.org/abs/1710.07388" target="_blank" rel="noopener">Multi-Task Learning for Speaker-Role Adaptation in Neural Conversation Models</a>: Yi Luan(University of Washington)</li></ul></li><li>Improving personalization with multiple losses<ul><li>16: <a href="https://arxiv.org/pdf/1606.00372.pdf" target="_blank" rel="noopener">Conversational Contextual Cues: The Case of Personalization and History for Response Ranking</a>: Rami Al-Rfou(Google .Inc)</li></ul></li></ol><h4 id="Challenge-Long-conversational-context"><a href="#Challenge-Long-conversational-context" class="headerlink" title="Challenge: Long conversational context"></a>Challenge: Long conversational context</h4><ol><li>It can be challenging for LSTM/GRU to encode very long context<ul><li>18: <a href="https://arxiv.org/abs/1805.04623" target="_blank" rel="noopener">Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</a>: Urvashi Khadelwal(Stanford University)</li></ul></li><li>Hierarchical Encoder-Decoder(HRED), <a href="https://github.com/urvashik/lm-context-analysis" target="_blank" rel="noopener">code</a><ul><li>16: <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160" target="_blank" rel="noopener">Building End-to-End Dialogue Systems Using Generative Hierarchical Neural Network Models</a>: Iulian V.Serban(University de Montreal), <a href="https://github.com/hsgodhia/hred" target="_blank" rel="noopener">code</a></li></ul></li><li>Hierarchical Latent Variable Encoder-Decoder(VHRED)<ul><li>17: <a href="http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf" target="_blank" rel="noopener">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>: Iulian V. Serban</li></ul></li></ol><h3 id="Grounded-conversation-models"><a href="#Grounded-conversation-models" class="headerlink" title="Grounded conversation models"></a>Grounded conversation models</h3><h4 id="A-Knowledge-Grounded-Neural-Conversation-Model"><a href="#A-Knowledge-Grounded-Neural-Conversation-Model" class="headerlink" title="A Knowledge-Grounded Neural Conversation Model"></a>A Knowledge-Grounded Neural Conversation Model</h4><ul><li>15: <a href="https://arxiv.org/pdf/1503.08895.pdf" target="_blank" rel="noopener">End-To-End Memory Networks</a>: Sainbayar Sukhbaatar(New York University)<ul><li><a href="https://github.com/carpedm20/MemN2N-tensorflow" target="_blank" rel="noopener">code1</a> via Tensorflow</li><li><a href="https://github.com/domluna/memn2n" target="_blank" rel="noopener">code2</a> via Tensorflow</li><li><a href="https://github.com/vinhkhuc/MemN2N-babi-python" target="_blank" rel="noopener">code3</a> for bAbI QA tasks</li></ul></li><li>17: <a href="https://arxiv.org/abs/1702.01932" target="_blank" rel="noopener">A Knowledge-Grounded Neural Conversation Model</a>: Marjan Gahzvininejad(USC)</li></ul><h4 id="Grounded-E2E-Dialogue-Systems"><a href="#Grounded-E2E-Dialogue-Systems" class="headerlink" title="Grounded E2E Dialogue Systems"></a>Grounded E2E Dialogue Systems</h4><ul><li>16: <a href="https://arxiv.org/abs/1611.08669" target="_blank" rel="noopener">Visual Dialog</a>: Abhishek Das(Georgia Institute of Tehhnology)<ul><li><a href="https://github.com/batra-mlp-lab/visdial" target="_blank" rel="noopener">code1</a> via Lua</li><li><a href="https://github.com/jiasenlu/visDial.pytorch" target="_blank" rel="noopener">code2</a> via Pytorch</li></ul></li><li>17: <a href="https://arxiv.org/abs/1701.08251" target="_blank" rel="noopener">Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation</a>: Nasrin Mostafazadeh(University of Rochster)</li><li>18: <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/04/huber2018chi.small_.pdf" target="_blank" rel="noopener">Emotional Dialogue Generation using Image-Grounded Language Models</a>:Bernd Huber(Harvard University)</li></ul><h3 id="Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue"><a href="#Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue" class="headerlink" title="Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)"></a>Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)</h3><ul><li>16: <a href="https://arxiv.org/abs/1606.01541" target="_blank" rel="noopener">Deep Reinforcement Learning for Dialogue Generation</a>:Jiwei Li(Stanford University)<ul><li><a href="https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow" target="_blank" rel="noopener">code1</a> via Tensorflow</li><li><a href="https://github.com/agsarthak/Goal-oriented-Dialogue-Systems" target="_blank" rel="noopener">code2</a> via keras</li><li><a href="https://github.com/jiweil/Neural-Dialogue-Generation" target="_blank" rel="noopener">code3</a> by Jiwei Li</li></ul></li></ul><h3 id="Data-and-evaluation"><a href="#Data-and-evaluation" class="headerlink" title="Data and evaluation"></a>Data and evaluation</h3><h4 id="Conversational-datasets-for-social-bots-E2E-dialogue-research"><a href="#Conversational-datasets-for-social-bots-E2E-dialogue-research" class="headerlink" title="Conversational datasets(for social bots, E2E dialogue research)"></a>Conversational datasets(for social bots, E2E dialogue research)</h4><ul><li>15: <a href="https://arxiv.org/abs/1512.05742" target="_blank" rel="noopener">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>: Iulian Vlad Serban(Universite de Montreal)</li></ul><h4 id="Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation"><a href="#Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation" class="headerlink" title="Evaluating E2E Dialogue Systems via Autumatic evaluation"></a>Evaluating E2E Dialogue Systems via Autumatic evaluation</h4><ol><li>Machine-Translation-Based Metric<ul><li>02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>02: <a href="http://www.mt-archive.info/HLT-2002-Doddington.pdf" target="_blank" rel="noopener">Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics</a>: George Doddington</li></ul></li><li>Sentence-level correlation of MT metrics:<ul><li>16: <a href="https://aclweb.org/anthology/D16-1230" target="_blank" rel="noopener">How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</a>: Chia-Wei Liu(McGill University)</li><li>15: <a href="http://www.aclweb.org/anthology/N15-1124" target="_blank" rel="noopener">Accurate Evaluation of Segment-level Machine Translation Metrics</a>: Yvette Graham(The University of Melbourne)</li></ul></li></ol><h4 id="The-importance-of-sample-size"><a href="#The-importance-of-sample-size" class="headerlink" title="The importance of sample size"></a>The importance of sample size</h4><ul><li>[<strong>duplicate</strong>] 02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>06: <a href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf" target="_blank" rel="noopener">Statistical Significance Tests for Machine Translation Evaluation</a>: Philipp Kowehn(MIT)</li></ul><h4 id="Corpus-level-Correlation"><a href="#Corpus-level-Correlation" class="headerlink" title="Corpus-level Correlation"></a>Corpus-level Correlation</h4><ul><li>[<strong>duplicate</strong>] 02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>[<strong>duplicate</strong>] 06: <a href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf" target="_blank" rel="noopener">Statistical Significance Tests for Machine Translation Evaluation</a>: </li></ul><h3 id="Chatbot-in-public"><a href="#Chatbot-in-public" class="headerlink" title="Chatbot in public"></a>Chatbot in public</h3><h4 id="Social-Bots-commercial-systems"><a href="#Social-Bots-commercial-systems" class="headerlink" title="Social Bots: commercial systems"></a>Social Bots: commercial systems</h4><ol><li>For end users<ul><li>Replika.ai system description: <a href="https://github.com/lukalabs/replika-research/blob/master/scai2017/replika_ai.pdf" target="_blank" rel="noopener">replika_ai</a>: Slides</li><li>XiaoIce:<br>15:<a href="https://www.nytimes.com/interactive/2015/07/27/science/chatting-with-xiaoice.html" target="_blank" rel="noopener">Chatting With Xiaoice</a>: News</li></ul></li><li>For bot developers<ul><li>[<strong>duplicate</strong>] Microsoft Personality chat:speaker embedding LSTM: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model" target="_blank" rel="noopener">code</a> via Pytorch</li><li>Microsoft Personality chat’s API: <a href="https://labs.cognitive.microsoft.com/en-us/project-personality-chat" target="_blank" rel="noopener">Project Personality Chat’s url</a> </li></ul></li></ol><h4 id="Open-Benchmarks"><a href="#Open-Benchmarks" class="headerlink" title="Open Benchmarks"></a>Open Benchmarks</h4><ol><li><p>Alexa Challenge</p><ul><li>website: <a href="https://developer.amazon.com/alexaprize/proceedings" target="_blank" rel="noopener">Alexa Prize Proceedings</a></li></ul></li><li><p>Dialogue System Technology Challenge(DSTC)</p><ul><li><a href="http://workshop.colips.org/dstc7" target="_blank" rel="noopener">DSTC7</a></li><li>Visual-Scene: <a href="https://github.com/hudaAlamri/DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge" target="_blank" rel="noopener">DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge 2018</a></li><li>background article:<br><a href="https://github.com/DSTC-MSR-NLP/DSTC7-End-to-End-Conversation-Modeling" target="_blank" rel="noopener">DSTC7-End-to-End-Conversation-Modeling 2018</a></li><li>Registration Link:<br><a href="http://workshop.colips.org/dstc7/call.html" target="_blank" rel="noopener">DSTC7 Registration</a></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/awesome-chatbot/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;blockquote&gt;
&lt;p&gt;论文列表格式&lt;br&gt;&amp;emsp;论文发表年份： 论文题目&amp;amp;论文链接：第一作者（第一作者所属学校/机构），代码
      
    
    </summary>
    
      <category term="AI" scheme="https://bupt.github.io/awesome-chatbot/categories/AI/"/>
    
    
      <category term="chatbot" scheme="https://bupt.github.io/awesome-chatbot/tags/chatbot/"/>
    
      <category term="conversationalAI" scheme="https://bupt.github.io/awesome-chatbot/tags/conversationalAI/"/>
    
      <category term="nlp" scheme="https://bupt.github.io/awesome-chatbot/tags/nlp/"/>
    
      <category term="paper" scheme="https://bupt.github.io/awesome-chatbot/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>对话AI的术语和学习地图</title>
    <link href="https://bupt.github.io/awesome-chatbot/2018/08/08/convAI-map-and-term/"/>
    <id>https://bupt.github.io/awesome-chatbot/2018/08/08/convAI-map-and-term/</id>
    <published>2018-08-08T15:25:39.000Z</published>
    <updated>2018-08-24T06:59:54.094Z</updated>
    
    <content type="html"><![CDATA[<script src="/awesome-chatbot/assets/js/APlayer.min.js"> </script><h2 id="chatbot基本篇"><a href="#chatbot基本篇" class="headerlink" title="chatbot基本篇"></a>chatbot基本篇</h2><ul><li><p>Natural language processing(自然语言处理/NLP)<br>自然语言处理是人工智能的一个子集领域。自然语言处理是一项包罗万象且相当复杂的技术，它包含许多子集，如自然语言理解。<br>NLP指的是机器理解人类输入的所有东西。为此，NLP引擎将使用许多工具，如NLU，总结算法，情绪分析，标记化等等。</p></li><li><p>Natural language understanding (自然语言理解/NLU)<br>自然语言理解是自然语言处理的一个子集。NLU和NLP经常被混淆，因为它们的意思非常接近。<br>NLU是NLP引擎中非常具体的部分，它检查话语并提取其实体和意图。用更通俗的话说，NLU允许机器理解用户在说什么。<br>说到聊天机器人，可以把NLU想象成阅读人类语言并识别文本不同部分的过程，把它分解成正确的意图和实体</p></li><li><p>Chatbot(聊天机器人)<br><code>chatbot</code>是一个可对话的计算机程序。但是<strong>对话agent</strong>可能是形容这个程序更好的词汇。</p></li><li><p>Utterance(表达)<br>用户对chatbot说的任何话，也可以看做是用户输入。例如，如果用户输入“给我看昨天的财经新闻”，整个句子就是<code>Utterance</code>。</p></li><li><p>Intent(意图))<br><code>Intent</code>代表了用户<code>Utterance</code>的意义。Chatbot将会根据用户一系列的<code>Intent</code>和对<code>Intent</code>的理解来回应用户。例如，如果用户输入“show me yesterday’s financial news”，用户的意图是检索金融标题列表。<code>Intent</code>通常是一个动词和一个名词，如“showNews”。</p></li><li><p>Entity(实体)<br><code>Entity</code>通常修饰<code>Intent</code>。例如，如果用户输入“show me yesterday’s financial news”，那么<code>Entity</code>是“yesterday”和“financial”。<code>Entity</code>会被赋予一个名称，例如“dateTime”和“newsType”。<code>Entity</code>有时也被称为<code>Slots</code>。</p></li></ul><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fu2otnnx3oj21r60x246f.jpg" alt=""></p><ul><li><p>Broadcast(广播)<br><code>Broadcast</code>是预先发送给用户的消息。它不是对用户输入的响应。<code>Broadcast</code>也被称为“订阅消息”，它相当于聊天机器人中的移动应用程序中的推送消息。</p></li><li><p>Ambiguity</p></li><li>Paraphrase</li><li>metric</li></ul><h2 id="术语进阶篇"><a href="#术语进阶篇" class="headerlink" title="术语进阶篇"></a>术语进阶篇</h2><h3 id="NLP常用术语"><a href="#NLP常用术语" class="headerlink" title="NLP常用术语"></a>NLP常用术语</h3><h4 id="词级别"><a href="#词级别" class="headerlink" title="词级别"></a>词级别</h4><ul><li>分词（Seg）</li><li>词性标注（POS）</li><li>命名实体识别（NER）</li><li>未登录词识别</li><li>词向量（word2vec）</li><li>词义消歧</li></ul><h4 id="句子级别"><a href="#句子级别" class="headerlink" title="句子级别"></a>句子级别</h4><ul><li>情感分析</li><li>关系提取</li><li>意图识别</li><li>依存句法分析（parser）</li><li>角色标注，</li><li>浅层语义分析，</li><li>指代消解</li></ul><h4 id="篇章级别"><a href="#篇章级别" class="headerlink" title="篇章级别"></a>篇章级别</h4><ul><li>信息抽取：</li><li>本体提取：</li><li>事件抽取：</li><li>主题提取：</li><li>文档聚类：</li><li>舆情分析：</li><li>篇章理解：</li><li>自动文摘：</li></ul><h4 id="常用基础算法："><a href="#常用基础算法：" class="headerlink" title="常用基础算法："></a>常用基础算法：</h4><ol><li><p>机器学习：</p><ul><li>隐马尔科夫（HMM）</li><li>条件随机场（CRF）</li><li>支持向量机（SVM）</li><li>语言模型</li><li>主题模型（LDA）</li><li>TF-IDF</li><li>互信息（PMI）</li><li>贝叶斯模型</li><li>概率图模型   </li></ul></li><li><p>深度学习:</p></li></ol><h3 id="Qustion-Answering-QA"><a href="#Qustion-Answering-QA" class="headerlink" title="Qustion Answering(QA)"></a>Qustion Answering(QA)</h3><h3 id="Reinfoecement-Learning-强化学习-RL"><a href="#Reinfoecement-Learning-强化学习-RL" class="headerlink" title="Reinfoecement Learning(强化学习/RL)"></a>Reinfoecement Learning(强化学习/RL)</h3><h3 id="Markov-Decision-Process-马尔科夫决策过程-MDP"><a href="#Markov-Decision-Process-马尔科夫决策过程-MDP" class="headerlink" title="Markov Decision Process(马尔科夫决策过程/MDP)"></a>Markov Decision Process(马尔科夫决策过程/MDP)</h3><h3 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP"></a>POMDP</h3><h3 id="Image-captioning"><a href="#Image-captioning" class="headerlink" title="Image captioning"></a>Image captioning</h3><h3 id="Phonology"><a href="#Phonology" class="headerlink" title="Phonology"></a>Phonology</h3><h3 id="分词（Segment）"><a href="#分词（Segment）" class="headerlink" title="分词（Segment）"></a>分词（Segment）</h3><p>中英文都存在分词的问题，不过相对来说，英文单词与单词之间本来就有空格进行分割，所以处理起来相对方便。但是中文书写是没有分隔符的，所以分词的问题就比较突出。分词常用的手段可以是基于字典的最长串匹配，据说可以解决85%的问题，但是歧义分词很难。另外就是当下主流的统计机器学习的办法。</p><h3 id="词性标注（Label）"><a href="#词性标注（Label）" class="headerlink" title="词性标注（Label）"></a>词性标注（Label）</h3><p>基于机器学习的方法里，往往需要对词的词性进行标注。标注的目的是用来表示，词的一种隐状态，隐藏状态构成的转移就构成了状态转移序列。例如：苏宁易购/n 投资/v 了/u 国际米兰/n。其中，n代表名词，v代表动词，n,v都是标注。以此类推。</p><h3 id="命名实体识别（Named-Entity-Recognition）"><a href="#命名实体识别（Named-Entity-Recognition）" class="headerlink" title="命名实体识别（Named Entity Recognition）"></a>命名实体识别（Named Entity Recognition）</h3><p>本质上还是标注问题的一种。只不过把标注细化了。比如，苏宁/cmp_s 易购/cmp_e 是/v B2C/n 电商/n。我们把苏宁易购 标注成cmp_s和cmp_e,分别表征公司名的起始和结束。这样，当遇上苏宁/云商/易购这种场景时，也可以完整得识别出它是一个公司名称。如果，按照传统的标注方式，苏宁/cmp 易购/cmp这样笼统地标注可能会有问题。</p><h3 id="句法分析（Syntax-Parsing）"><a href="#句法分析（Syntax-Parsing）" class="headerlink" title="句法分析（Syntax Parsing）"></a>句法分析（Syntax Parsing）</h3><p>句法分析往往是一种基于规则的专家系统。当然也不是说它不能用统计学的方法进行构建，不过最初的时候，还是利用语言学专家的知识来构建的。句法分析的目的是解析句子的中各个成分的依赖关系。所以，往往最终生成的结果，是一棵句法分析树。句法分析可以解决传统词袋模型不考虑上下文的问题。比如，张三是李四的领导；李四是张三的领导。这两句话，用词袋模型是完全相同的，但是句法分析可以分析出其中的主从关系，真正理清句子的关系。</p><h3 id="指代消解-Anaphora-Resolution"><a href="#指代消解-Anaphora-Resolution" class="headerlink" title="指代消解(Anaphora Resolution)"></a>指代消解(Anaphora Resolution)</h3><p>中文中代词出现的频率很高，它的作用的是用来表征前文出现过的人名、地名等词。例如，苏宁易购坐落在南京，这家公司目前位于中国B2C市场前三。在这句话中，其实“苏宁易购”这个词出现了2次，“这家公司”指代的就是苏宁易购。但是出于中文的习惯，我们不会把“苏宁易购”再重复一遍。</p><h2 id="AI模型篇"><a href="#AI模型篇" class="headerlink" title="AI模型篇"></a>AI模型篇</h2><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h3 id="Triplet-loss"><a href="#Triplet-loss" class="headerlink" title="Triplet loss"></a>Triplet loss</h3><h3 id="Machine-Reading-Comprehension-MRC"><a href="#Machine-Reading-Comprehension-MRC" class="headerlink" title="Machine Reading Comprehension(MRC)"></a>Machine Reading Comprehension(MRC)</h3><h3 id="Knowledge-Base-QA-KBQA"><a href="#Knowledge-Base-QA-KBQA" class="headerlink" title="Knowledge Base-QA(KBQA)"></a>Knowledge Base-QA(KBQA)</h3><ul><li>WordNet(1998)</li><li>Freebase(2008)</li><li>Yago(2007)</li></ul><h3 id="Knowledge-base-completion-KBC"><a href="#Knowledge-base-completion-KBC" class="headerlink" title="Knowledge base completion(KBC)"></a>Knowledge base completion(KBC)</h3><h2 id="chatbot领域学习地图："><a href="#chatbot领域学习地图：" class="headerlink" title="chatbot领域学习地图："></a>chatbot领域学习地图：</h2><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fue50ug6o9j217m88pb2c.jpg" alt=""></p><blockquote><p>参考与引用</p><ol><li><a href="https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/</a></li><li><a href="https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4" target="_blank" rel="noopener">https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4</a></li><li><a href="https://blog.ubisend.com/discover-chatbots/chatbot-glossary" target="_blank" rel="noopener">https://blog.ubisend.com/discover-chatbots/chatbot-glossary</a></li><li><a href="https://blog.csdn.net/wangongxi/article/details/52662177" target="_blank" rel="noopener">https://blog.csdn.net/wangongxi/article/details/52662177</a></li><li><a href="https://www.jianshu.com/p/d7ec29abbcb8" target="_blank" rel="noopener">https://www.jianshu.com/p/d7ec29abbcb8</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/awesome-chatbot/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;chatbot基本篇&quot;&gt;&lt;a href=&quot;#chatbot基本篇&quot; class=&quot;headerlink&quot; title=&quot;chatbo
      
    
    </summary>
    
      <category term="AI" scheme="https://bupt.github.io/awesome-chatbot/categories/AI/"/>
    
    
      <category term="chatbot" scheme="https://bupt.github.io/awesome-chatbot/tags/chatbot/"/>
    
      <category term="conversationalAI" scheme="https://bupt.github.io/awesome-chatbot/tags/conversationalAI/"/>
    
      <category term="nlp" scheme="https://bupt.github.io/awesome-chatbot/tags/nlp/"/>
    
  </entry>
  
</feed>
